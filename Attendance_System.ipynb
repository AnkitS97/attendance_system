{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mtcnn.mtcnn import MTCNN\n",
    "# import cv2\n",
    "from keras_facenet.model import *\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3de3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"square image.png\")\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "result = detector.detect_faces(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1, width, height = result[0]['box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = abs(x1), abs(y1)\n",
    "x2, y2 = x1 + width, y1 + height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cea497",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = img_rgb[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('face_img.png', cv2.cvtColor(face, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionResNetV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = os.path.join(\"keras_facenet\", \"weights\", \"facenet_keras_weights.h5\")\n",
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1968dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19051f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(x):\n",
    "    return x/np.sqrt(np.sum(np.multiply(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = cv2.resize(face, (160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = np.expand_dims(face, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df088c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = preprocess_input(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6af46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_euclidean_distance(source, target):\n",
    "    distance = source - target\n",
    "    distance = np.sum(np.multiply(distance, distance))\n",
    "    distance = np.sqrt(distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = detector.detect_faces(img_rgb)\n",
    "    x1, y1, width, height = result[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = img_rgb[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (160, 160))\n",
    "    face = face.astype('float32')\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face - mean) / std\n",
    "    face = np.expand_dims(face, axis=0)\n",
    "    face = preprocess_input(face)\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = l2_normalize(model.predict(face))[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_embeddings = l2_normalize(model.predict(preprocess_image('jenifer1.jpg')))[0, :]\n",
    "img2_embeddings = l2_normalize(model.predict(preprocess_image('download.jpg')))[0, :]\n",
    "\n",
    "dist = find_euclidean_distance(img1_embeddings, img2_embeddings)\n",
    "\n",
    "threshold = 0.05\n",
    "\n",
    "if dist < threshold:\n",
    "    print(dist)\n",
    "    print('They are the same person.')\n",
    "else:\n",
    "    print(dist)\n",
    "    print('DIfferent person.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97890ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(path, model):\n",
    "\n",
    "    img = cv2.imread(path, 1)\n",
    "    img = img[...,::-1]\n",
    "    img = cv2.resize(img, (96, 96))\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_embedding = img_to_encodding('anjelina1.jpg', model)\n",
    "img2_embedding = img_to_encodding('jenifer2.jpg', model)\n",
    "\n",
    "dist = np.linalg.norm(img1_embedding - img2_embedding)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78caf6",
   "metadata": {},
   "source": [
    "# Deep Learning Specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b450d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13662c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha=0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=triplet_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0afc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_from_FaceNet(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5bcc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('face_reco_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('face_reco_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "face1 = preprocess_image(\"anjelina1.jpg\", detector)\n",
    "face2 = preprocess_image(\"jenifer2.jpg\", detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session =tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding1 = img_to_encoding(\"anjelina1.jpg\", model)\n",
    "encoding2 = img_to_encoding(\"jenifer2.jpg\", model)\n",
    "\n",
    "dist = np.linalg.norm(encoding - database[identity])\n",
    "\n",
    "if dist < 0.7:\n",
    "    print(\"welcome in!\")\n",
    "else:\n",
    "    print(\"please go away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40730b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"anjelina1.jpg\", 1)\n",
    "img = img[...,::-1]\n",
    "img = cv2.resize(img, (96, 96))\n",
    "img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "x_train = np.array([img])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    img = img[...,::-1]\n",
    "    img = cv2.resize(img, (96, 96))\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84947b",
   "metadata": {},
   "source": [
    "# New Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202cd695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from keras_facenet import model as resnet\n",
    "import numpy as np\n",
    "import tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04758ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/model-20170512-110547.ckpt-250000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c20f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53163e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\attendance system\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "c:\\users\\user\\anaconda3\\envs\\attendance system\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/model-20170512-110547.ckpt-250000\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    sess = tf.compat.v1.Session()\n",
    "    x = tf.compat.v1.placeholder('float', [None,160,160,3])\n",
    "    embeddings = tf.nn.l2_normalize(resnet.inference(x, 0.6, phase_train=False)[0], 1, 1e-10)\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6bb2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0fc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b31871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(path, detector):\n",
    "    img = cv2.imread(path, 1)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = detector.detect_faces(img_rgb)\n",
    "    x1, y1, width, height = result[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = img_rgb[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (160, 160))\n",
    "    face = np.expand_dims(face, axis=0)\n",
    "    face = face/255.0\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a70f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027D0CEC3D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "face1 = preprocess_img('download.jpg', detector)\n",
    "face2 = preprocess_img('anjelina1.jpg', detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f950c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "face1_embed = sess.run(embeddings, feed_dict = {x : face1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f953696",
   "metadata": {},
   "outputs": [],
   "source": [
    "face2_embed = sess.run(embeddings, feed_dict = {x : face2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "479cd207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3954519\n"
     ]
    }
   ],
   "source": [
    "dist = np.linalg.norm(face1_embed[0] - face2_embed[0])\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37148e83",
   "metadata": {},
   "source": [
    "Chris v Chris\n",
    "0.5928121\n",
    "\n",
    "jenifer v jenifer 0.70\n",
    "\n",
    "anjelina v anjelina 0.679\n",
    "\n",
    "jenifer v anjelina 1.310 1.505 1.546\n",
    "\n",
    "Theshold = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb768050",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'root'\n",
    "\n",
    "password = 'root'\n",
    "\n",
    "db_name = 'AttendanceSystem'\n",
    "\n",
    "# connection_url = f\"mongodb+srv://{username}:{password}@cluster0.oxlmy.mongodb.net/{db_name}?ssl=true&ssl_cert_reqs=CERT_NONE\"\n",
    "# client = pymongo.MongoClient(connection_url, connect=False)\n",
    "\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://root:root@cluster0.oxlmy.mongodb.net/AttendanceSystem?retryWrites=true&w=majority\")\n",
    "\n",
    "\n",
    "db = client[db_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'Employees'\n",
    "\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "face1_embed_db = [i.item() for i in face1_embed[0]]\n",
    "\n",
    "rec = dict()\n",
    "\n",
    "rec['name'] = 'chris hemsworth'\n",
    "rec['embeddings'] = face1_embed_db\n",
    "\n",
    "collection.insert_one(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dict()\n",
    "\n",
    "query['name'] = 'chris hemsworth'\n",
    "\n",
    "res = collection.find_one(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = res['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.linalg.norm(face2_embed[0] - embed)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94af2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('photo.jpeg', 1)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "result = detector.detect_faces(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235360e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f97343bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = result[0]['box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb620c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = cv2.rectangle(img,(rect[0],rect[1]),(rect[0] + rect[2],rect[1]+rect[3]),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16a789e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = cv2.rectangle(img,(rect[0],rect[1]+rect[3] + 4),(rect[0] + size[0],rect[1]+rect[3] + 4 + size[1]),(0,255,0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62183219",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = cv2.putText(new_img, \"Ankit Sawant - \" + tim,(rect[0],rect[1]+rect[3] + 4 + size[1]),cv2.FONT_HERSHEY_SIMPLEX,scale,(255,255,255),1,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "131322e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('save_img.jpg', new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "235391cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_font_scale(text, width):\n",
    "    for scale in reversed(range(0, 10, 1)):\n",
    "        textSize = cv2.getTextSize(text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=scale/10, thickness=1)\n",
    "        new_width = textSize[0][0]\n",
    "        if (new_width <= width - width*0.3):\n",
    "            return scale/10, textSize[0]\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4635f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale, size = get_optimal_font_scale(\"Ankit Sawant - \" + tim, img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4a479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ad56a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9792081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = ct.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f23d7c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(str(tim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bd0f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = ct.day\n",
    "month = ct.month\n",
    "year = ct.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2238f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15/4/2021'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(day) + '/' + str(month) + '/' + str(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb1494ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = str(tim).split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2670cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
